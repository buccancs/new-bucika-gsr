# Chapter 1: Introduction

## 1.1 Motivation and Research Context

In recent years, interest in physiological computing has grown ---
using bodily signals to infer a person's internal states in health
monitoring, affective computing, and human-computer interaction. One
especially valuable physiological signal is the Galvanic Skin Response
(GSR) (also known as electrodermal activity or skin conductance). GSR
measures subtle changes in the skin's electrical conductance caused by
sweat gland activity, which is directly modulated by the sympathetic
nervous system [1]. These involuntary changes reflect emotional
arousal and stress, making GSR a widely accepted indicator of autonomic
nervous system activity [1]. GSR is used in clinical psychology (e.g.,
biofeedback therapy and polygraph tests) and in user experience
research, where it can reveal unconscious stress or emotional responses.
Even consumer technology now leverages skin conductance: modern
smartwatches from Apple and Samsung include sensors for continuous
stress monitoring via GSR or related metrics [2]. This surge of
interest underscores the motivation to harness physiological signals
like GSR in everyday contexts.

Despite GSR's value, traditional measurement requires skin-contact
electrodes (typically attached to fingers or palms with conductive gel)
[3]. This method is obtrusive: wires and electrodes restrict movement,
and long-term use can cause discomfort or skin irritation [3]. These limitations make it difficult to use GSR outside the lab.
Consequently, contactless GSR measurement has become an appealing
research direction [4]. The idea is to infer GSR (or the underlying
psychophysiological arousal) using remote sensors that require no
physical contact with the user. For example, thermal infrared cameras
detect subtle skin temperature changes from blood flow and perspiration,
offering a proxy for stress responses [5].

Facial thermal imaging is promising as a complementary measure in
emotion research, given that stress and thermoregulation are linked
(e.g., perspiration causes cooling) [5]. Similarly, high-resolution
RGB video combined with advanced computer vision can non-invasively
capture other physiological signals. Prior work shows that heart rate
and breathing can be measured from video of a person's face or body
[6]. These developments suggest that multi-modal sensing ---
combining traditional biosensors with imaging --- could enable
contactless physiological monitoring in the near future. Affective
computing research indicates that fusing multiple modalities (e.g., GSR,
heart rate, facial thermal data) can capture emotional or stress states
more robustly [1].

However, significant challenges remain. A key research gap is the lack
of an integrated platform to synchronise these diverse data streams.
Most prior studies addressed contactless GSR estimation in isolation or
in highly controlled conditions, often using separate devices that were
not synchronised in real time [7]. For instance, thermal
cameras and wearable GSR sensors have typically been used independently,
with any data fusion done post hoc. This piecemeal approach complicates
machine learning model development, since models require well-aligned
datasets of inputs (e.g., video or thermal data) and outputs (measured
GSR). Clearly, a multi-modal data collection platform is needed to
record GSR and other sensor modalities simultaneously with proper
synchronisation. Such a platform would allow researchers to gather rich,
time-aligned datasets. For example, thermal video of a participant's
face could be recorded in sync with their GSR signal. These combined
data would lay the groundwork for training and validating models that
infer GSR from camera-based sensors. The primary contribution of this
thesis is the development of just such a platform: a modular,
multi-sensor system for synchronised physiological data acquisition
designed for future GSR prediction research. In summary, this work is
motivated by recent trends in physiological computing and multimodal
sensing, and by the need for robust, synchronised datasets to advance
contactless GSR measurement.

## 1.2 Research Problem and Objectives

Given this context, the research problem can be stated as follows:
there is no system readily available to synchronously collect GSR
signals alongside complementary data streams (such as thermal and visual
data) in naturalistic settings, which hinders the development of machine
learning models for contactless GSR prediction. While traditional GSR
sensors provide reliable ground truth, they are intrusive in real-world
use, and fully contactless approaches remain unvalidated or imprecise
[8]. Bridging this gap requires a platform that records multiple
modalities simultaneously --- for example, capturing a person's skin
conductance with a wearable sensor while concurrently recording thermal
and visual data. Crucially, all data must be tightly time-synchronised
to allow meaningful correlation and learning. The absence of such an
integrated system is the core problem that this thesis addresses.

The objective of this research is to design and implement a
multi-modal physiological data collection platform to create a
synchronised dataset for future GSR prediction models. Unlike end-user
applications or final predictive systems, this work focuses on the data
acquisition infrastructure --- essentially building the foundation on
which real-time GSR inference algorithms can be developed later. Note
that real-time GSR prediction is outside the scope of this thesis.
Instead, the project aims to facilitate future machine learning by providing a
robust way to gather ground-truth GSR and candidate predictor signals
together. The following specific objectives have been defined to achieve
this aim:

- Objective 1: Multi-Modal Platform Development. Design and develop
  a modular data acquisition system capable of recording synchronised
  physiological and imaging data. This involves integrating a wearable
  GSR sensor and camera-based sensors into one platform. In practice,
  the system uses a research-grade Shimmer3 GSR+ sensor [8] for
  ground-truth skin conductance, a Topdon TC001 thermal camera [20]
  attached to a smartphone for thermal video, and the smartphone's
  built-in RGB camera for high-resolution video. A smartphone-based
  sensor node will be coordinated with a desktop controller to start and
  stop recordings in unison and to timestamp all data consistently. The
  architecture should ensure that all modalities are recorded
  simultaneously with millisecond-level alignment.

- Objective 2: Synchronised Data Acquisition and Management.
  Implement methods for precise time synchronisation and data handling
  across devices. A custom control and synchronisation layer (in
  Python) will coordinate the sensor node(s) and ensure that GSR
  readings, thermal frames, and RGB frames are all logged with
  synchronised timestamps. This includes establishing a reliable
  communication protocol between the smartphone and the PC controller to
  transmit control commands and streaming data [9]. Data management
  is also addressed: multi-modal data will be stored in appropriate
  formats with metadata for easy combination and analysis. The outcome
  should be a well-synchronised dataset (e.g., physiological sample
  timestamps aligned with video frame times) that can serve as a
  training corpus for machine learning.

- Objective 3: System Validation through Pilot Data Collection.
  Evaluate the integrated platform's performance and data integrity in
  a real recording scenario. Test recording sessions will be conducted to
  verify that the system meets research-grade requirements. For example,
  pilot experiments may involve human participants performing tasks
  designed to elicit varying GSR responses (stress, stimuli, etc.) while
  the platform records all modalities. Validation will focus on temporal
  synchronisation accuracy (e.g., confirming events are correctly
  aligned across sensor streams) and the quality of the recorded signals
  (e.g., GSR signal-to-noise ratio, thermal image resolution). The collected data will be analysed to ensure that GSR signals and
  corresponding thermal/RGB data show expected correlations or
  time-locked changes. Successful validation will demonstrate that the
  platform can reliably capture synchronised multi-modal data suitable
  for subsequent machine learning analysis. (Developing the predictive
  model itself is left for future work; here the focus is on validating the
  data pipeline that would feed such a model.)

By accomplishing these objectives, this thesis delivers a multi-sensor
data collection platform that fills the current gap. The platform will
enable researchers to build multimodal datasets for GSR prediction,
helping pave the way toward fully contactless, real-time stress
monitoring. The project emphasises a flexible, extensible setup --- a modular
sensing system --- that integrates the devices used here (GSR sensor
and thermal/RGB cameras) and can be extended to additional modalities in
the future. Ultimately, this work lays the groundwork for future studies
to train and test machine learning algorithms to estimate GSR from
camera data, by first solving the critical challenge of acquiring
synchronised ground-truth data.

## 1.3 Thesis Outline

This thesis is organised into six chapters, following a logical
progression from background concepts through system development to
evaluation:

- Chapter 2 \-- Background and Research Context: This chapter
  reviews relevant literature and technical background. It covers
  physiological computing and emotion recognition, the importance of GSR
  in stress research, and prior approaches to contactless physiological
  measurement. Key related works in multimodal data collection and
  sensor fusion are examined to show the state of the art and the gap
  addressed by this research. The chapter also explains the rationale
  for choosing the specific sensors (Shimmer3 GSR+ and Topdon thermal
  camera) and the expected advantages of a multimodal approach.

- Chapter 3 \-- Requirements Analysis: This chapter defines the
  specific requirements for the data collection platform. The research
  problem is analysed to derive both functional requirements (e.g.,
  the ability to record multiple streams concurrently, synchronisation
  accuracy, user interface needs) and non-functional requirements
  (e.g., system reliability, timing precision, data storage
  considerations). Use-case scenarios and user stories illustrate these
  requirements in practical research situations. By the end of this
  chapter, the scope of the system and the criteria for success are
  clearly established.

- Chapter 4 \-- System Design and Architecture: This chapter
  describes the design of the proposed multi-modal recording system,
  presenting the overall architecture and how hardware and software
  components interact. Key design decisions are discussed (e.g.,
  choosing a distributed setup with an Android smartphone as a sensor
  hub and a PC as the central controller [9]). The chapter details
  how the hardware integration is achieved (mounting the thermal
  camera on the phone, Bluetooth pairing with the GSR sensor, etc.) and
  how the software is structured into modules for camera capture, sensor
  communication, network synchronisation, and data logging. Diagrams
  illustrate the flow of data and control commands between the Android
  app and the Python desktop application. The design emphasises
  modularity, so each sensing component (thermal, RGB, GSR) operates in
  sync under the coordination of the central controller. Important
  considerations such as timestamp synchronisation, latency handling,
  and error recovery are also described.

- Chapter 5 \-- Evaluation and Testing: This chapter documents the
  testing methodology, implementation, and results for the multi-sensor
  recording system. The testing covers unit tests, integration tests,
  and system-level performance evaluation. Unit tests on Android
  (JUnit/Robolectric) and PC (pytest/unittest) verify functionality,
  including error handling and security features. Integration tests use
  a DeviceSimulator and a JSON-based message protocol (with optional
  TLS) to validate multi-device synchronisation. System performance is
  evaluated through 8-hour endurance testing, memory leak detection (via
  linear regression analysis), and CPU/throughput monitoring with
  resource utilisation tracking. The results confirm that the system
  meets its functionality, reliability, and performance requirements,
  demonstrating research-grade reliability for scientific data
  collection. This validation shows the platform's capability as a data
  collection tool for future GSR prediction research. Any observed
  limitations (e.g., minor synchronisation offsets or sensor noise
  issues) are noted to guide future improvements.

- Chapter 6 \-- Conclusion and Future Work: This final chapter
  summarises the thesis contributions and reflects on how well the
  objectives were achieved. It highlights the success of developing the
  multi-modal data collection platform and discusses its significance
  for the research community. The chapter also addresses the current
  system's limitations (e.g., lack of real-time analysis or untested
  environments). Finally, it outlines future work and recommendations,
  including next steps like using the collected data to train GSR
  prediction models, improving the platform's real-time capabilities,
  and extending the system with additional sensors (such as heart rate
  or respiration) to broaden its application. These future directions
  provide a roadmap for moving from this data collection foundation
  toward full-fledged real-time GSR inference in subsequent
  research.

## References

See [centralised references](references.md) for all citations used throughout this thesis.
