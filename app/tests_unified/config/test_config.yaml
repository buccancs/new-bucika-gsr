# Unified Test Configuration for Multi-Sensor Recording System
# Consolidates configuration from multiple testing frameworks

# Quality thresholds for research-grade validation
quality_thresholds:
  # Test success rates by level
  unit_tests:
    minimum_success_rate: 0.95
    maximum_execution_time: 60.0
    minimum_coverage: 0.80
    
  integration_tests:
    minimum_success_rate: 0.90
    maximum_execution_time: 180.0
    minimum_coverage: 0.75
    
  system_tests:
    minimum_success_rate: 0.95
    maximum_execution_time: 600.0
    minimum_coverage: 0.70
    
  performance_tests:
    minimum_success_rate: 0.85
    maximum_execution_time: 1800.0
    minimum_coverage: 0.60

  # Research-specific quality requirements
  research_validation:
    sync_precision_ms: 1.0
    data_quality_score: 0.8
    measurement_accuracy: 0.95
    temporal_stability_drift_ms_per_hour: 1.0
    cross_platform_sync_variance_ms: 50.0

  # Performance benchmarks
  performance_benchmarks:
    memory_usage_mb_max: 1024
    cpu_utilization_percent_avg: 60
    cpu_utilization_percent_max: 85
    network_latency_ms_avg: 100
    network_latency_ms_max: 50
    data_throughput_mbps_per_device: 10
    data_throughput_mbps_aggregate: 100
    error_recovery_rate: 0.80
    error_recovery_time_seconds: 5
    device_count_supported: 8

# Test execution configuration
test_execution:
  # Timeout settings (seconds)
  timeouts:
    unit: 60
    integration: 180
    system: 600
    performance: 1800
    evaluation: 900
    quick_mode: 120
    
  # Parallel execution settings
  parallel:
    enabled: true
    max_workers: 4
    safe_for_parallel:
      - unit
      - integration
    sequential_only:
      - hardware_loop
      - visual
      - load
  
  # Retry settings
  retry:
    max_retries: 2
    retry_delays: [1, 2, 5]
    retryable_failures:
      - network
      - hardware
      - timing
  
  # Resource monitoring
  monitoring:
    collect_metrics: true
    resource_limits:
      memory_mb: 2048
      cpu_percent: 90
      disk_space_mb: 1024
    
# Test environments and modes
environments:
  # Development environment
  development:
    quick_mode: true
    verbose_logging: true
    collect_coverage: false
    parallel_execution: true
    hardware_tests: false
    
  # Continuous Integration environment  
  ci:
    quick_mode: false
    verbose_logging: false
    collect_coverage: true
    parallel_execution: true
    hardware_tests: false
    headless_mode: true
    
  # Research validation environment
  research:
    quick_mode: false
    verbose_logging: true
    collect_coverage: true
    parallel_execution: false
    hardware_tests: true
    strict_quality_validation: true
    statistical_validation: true
    
  # Production readiness testing
  production:
    quick_mode: false
    verbose_logging: false
    collect_coverage: true
    parallel_execution: true
    hardware_tests: true
    endurance_testing: true
    load_testing: true

# Test data and fixtures
test_data:
  # Synthetic data generation
  synthetic_data:
    enabled: true
    sample_rates: [100, 250, 500, 1000]  # Hz
    data_types: ['gsr', 'thermal', 'camera', 'audio']
    session_durations: [10, 30, 60, 300]  # seconds
    
  # Mock configurations
  mocks:
    hardware_simulation: true
    network_simulation: true
    sensor_simulation: true
    timing_simulation: true
    
  # Test fixtures
  fixtures:
    shared_fixtures_enabled: true
    cleanup_after_tests: true
    preserve_test_artifacts: false

# Platform-specific configurations
platforms:
  android:
    emulator_startup_timeout: 120
    app_startup_timeout: 30
    device_discovery_timeout: 10
    test_apk_install: true
    
  desktop:
    gui_testing_enabled: true
    headless_mode_available: true
    virtual_display_resolution: "1920x1080"
    
  web:
    browsers: ['chromium', 'firefox', 'webkit']
    headless_browsers: true
    browser_startup_timeout: 30

# Reporting and output
reporting:
  # Report formats
  formats:
    junit_xml: true
    html_report: true
    json_summary: true
    markdown_summary: true
    
  # Report content
  include_metrics: true
  include_screenshots: true
  include_logs: true
  include_coverage: true
  include_performance_data: true
  
  # Output directories
  output_dir: "test_results"
  artifacts_dir: "test_artifacts"
  logs_dir: "test_logs"
  
  # Report retention
  keep_last_n_reports: 10
  cleanup_old_reports: true

# Integration with external tools
integrations:
  # Version control
  git:
    collect_commit_info: true
    include_diff_context: true
    
  # Issue tracking
  github:
    create_issues_for_failures: false
    update_pr_status: true
    
  # Monitoring and alerting
  monitoring:
    send_notifications: false
    webhook_url: null
    alert_on_failure_rate: 0.20
    
# Migration and compatibility settings
migration:
  # Backward compatibility
  legacy_test_support: true
  preserve_original_markers: true
  maintain_original_structure: false
  
  # Migration paths
  source_directories:
    - "tests/"
    - "evaluation_suite/"
    - "PythonApp/"
  
  target_mapping:
    "tests/unit/": "tests_unified/unit/"
    "tests/integration/": "tests_unified/integration/"
    "tests/e2e/": "tests_unified/system/"
    "tests/load/": "tests_unified/performance/load/"
    "tests/browser/": "tests_unified/browser/"
    "tests/visual/": "tests_unified/visual/"
    "tests/hardware/": "tests_unified/hardware/"
    "evaluation_suite/foundation/": "tests_unified/evaluation/foundation/"
    "evaluation_suite/integration/": "tests_unified/integration/"
    "evaluation_suite/performance/": "tests_unified/performance/"
    "PythonApp/production/": "tests_unified/performance/endurance/"