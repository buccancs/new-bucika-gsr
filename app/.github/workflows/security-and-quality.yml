name: Security and Quality

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main, develop ]
  schedule:
    # Run weekly security and quality analysis on Mondays at 9 AM UTC
    - cron: '0 9 * * 1'
  workflow_dispatch:
    inputs:
      scan_type:
        description: 'Type of scan to run'
        required: true
        default: 'full'
        type: choice
        options:
          - full
          - security-only
          - quality-only
          - quick

env:
  PYTHON_VERSION: '3.10'
  JAVA_VERSION: '17'

jobs:
  # Python security and quality analysis
  python-security-quality:
    name: Python Security & Quality
    runs-on: ubuntu-latest
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      with:
        fetch-depth: 0  # Full history for better analysis
    
    - name: Set up Python ${{ env.PYTHON_VERSION }}
      uses: actions/setup-python@v5
      with:
        python-version: ${{ env.PYTHON_VERSION }}
        cache: 'pip'
    
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -e .
        pip install -r test-requirements.txt
        pip install bandit safety pip-audit radon xenon mypy complexity-report
    
    - name: Security vulnerability scan
      id: security-scan
      run: |
        echo "üîí Running security vulnerability scan..."
        mkdir -p security-reports
        
        # Python dependency vulnerabilities
        echo "::group::Python dependency scan (Safety)"
        safety scan --json > security-reports/safety-report.json || true
        safety scan --short-report || true
        echo "::endgroup::"
        
        echo "::group::Python dependency scan (pip-audit)"
        pip-audit --format=json --output=security-reports/pip-audit-report.json || true
        pip-audit || true
        echo "::endgroup::"
        
        # Code security analysis
        echo "::group::Code security analysis (Bandit)"
        bandit -r PythonApp/ shared_protocols/ -f json -o security-reports/bandit-report.json || true
        bandit -r PythonApp/ shared_protocols/ -ll
        echo "::endgroup::"
        
        # Check for critical vulnerabilities
        CRITICAL_VULNS=0
        if [ -f security-reports/safety-report.json ]; then
          CRITICAL_VULNS=$(python -c "
        import json, sys
        try:
            with open('security-reports/safety-report.json') as f:
                data = json.load(f)
            critical = sum(1 for v in data.get('vulnerabilities', []) if v.get('severity') == 'critical')
            print(critical)
        except:
            print(0)
        " 2>/dev/null || echo "0")
        fi
        
        echo "critical_vulnerabilities=$CRITICAL_VULNS" >> $GITHUB_OUTPUT
    
    - name: Code quality analysis
      id: quality-analysis
      run: |
        echo "üìä Running code quality analysis..."
        mkdir -p quality-reports
        
        # Formatting and style checks
        echo "::group::Code formatting (Black)"
        black --check --diff PythonApp/ shared_protocols/ > quality-reports/black-report.txt || true
        echo "::endgroup::"
        
        echo "::group::Import sorting (isort)"
        isort --check-only --diff PythonApp/ shared_protocols/ > quality-reports/isort-report.txt || true
        echo "::endgroup::"
        
        echo "::group::Style checking (flake8)"
        flake8 PythonApp/ shared_protocols/ --output-file=quality-reports/flake8-report.txt || true
        echo "::endgroup::"
        
        echo "::group::Static analysis (pylint)"
        pylint PythonApp/ shared_protocols/ --output-format=json > quality-reports/pylint-report.json || true
        echo "::endgroup::"
        
        # Complexity analysis
        echo "::group::Complexity analysis"
        radon cc PythonApp/ shared_protocols/ --json > quality-reports/cyclomatic-complexity.json
        radon mi PythonApp/ shared_protocols/ --json > quality-reports/maintainability-index.json
        radon hal PythonApp/ shared_protocols/ --json > quality-reports/halstead-complexity.json
        echo "::endgroup::"
        
        # Type checking
        echo "::group::Type checking (MyPy)"
        mypy PythonApp/ shared_protocols/ --json-report quality-reports/mypy-report || true
        echo "::endgroup::"
        
        # Check complexity thresholds
        echo "::group::Complexity threshold validation"
        COMPLEX_FUNCTIONS=$(xenon --max-absolute C --max-modules B --max-average A PythonApp/ shared_protocols/ 2>&1 | grep -c "too complex" || echo "0")
        echo "complex_functions=$COMPLEX_FUNCTIONS" >> $GITHUB_OUTPUT
        echo "::endgroup::"
    
    - name: Generate quality score
      id: quality-score
      run: |
        echo "üéØ Calculating overall quality score..."
        
        python -c "
        import json
        import os
        
        # Calculate quality score based on various metrics
        score = 10.0
        
        # Deduct for complexity issues
        complex_functions = int(os.environ.get('COMPLEX_FUNCTIONS', 0))
        score -= min(complex_functions * 0.5, 3.0)
        
        # Deduct for security vulnerabilities
        critical_vulns = int(os.environ.get('CRITICAL_VULNS', 0))
        score -= min(critical_vulns * 2.0, 4.0)
        
        # Additional deductions for code quality issues
        try:
            with open('quality-reports/pylint-report.json') as f:
                pylint_data = json.load(f)
            errors = sum(1 for msg in pylint_data if msg.get('type') == 'error')
            warnings = sum(1 for msg in pylint_data if msg.get('type') == 'warning')
            score -= min(errors * 0.3 + warnings * 0.1, 2.0)
        except:
            pass
        
        score = max(score, 0.0)
        
        print(f'Overall quality score: {score:.1f}/10.0')
        
        # Create summary
        summary = {
            'overall_score': score,
            'critical_vulnerabilities': critical_vulns,
            'complex_functions': complex_functions,
            'timestamp': '$(date -Iseconds)'
        }
        
        with open('quality-summary.json', 'w') as f:
            json.dump(summary, f, indent=2)
        "
        
        env:
          COMPLEX_FUNCTIONS: ${{ steps.quality-analysis.outputs.complex_functions }}
          CRITICAL_VULNS: ${{ steps.security-scan.outputs.critical_vulnerabilities }}
    
    - name: Upload Python security and quality reports
      uses: actions/upload-artifact@v4
      if: always()
      with:
        name: python-security-quality-reports
        path: |
          security-reports/
          quality-reports/
          quality-summary.json
        retention-days: 30

  # Android security and quality analysis
  android-security-quality:
    name: Android Security & Quality
    runs-on: ubuntu-latest
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
    
    - name: Set up JDK ${{ env.JAVA_VERSION }}
      uses: actions/setup-java@v4
      with:
        java-version: ${{ env.JAVA_VERSION }}
        distribution: 'temurin'
    
    - name: Cache Gradle dependencies
      uses: actions/cache@v4
      with:
        path: |
          ~/.gradle/caches
          ~/.gradle/wrapper
        key: ${{ runner.os }}-gradle-security-${{ hashFiles('**/*.gradle*') }}
    
    - name: Setup Gradle
      run: |
        chmod +x ./gradlew
        ./gradlew --stop || true
        rm -rf ~/.gradle/caches/*/dependencies-accessors/ || true
        ./gradlew --version --no-daemon
    
    - name: Android security analysis
      id: android-security
      run: |
        echo "üîí Running Android security analysis..."
        mkdir -p android-security-reports
        
        # Check for security issues in Android code
        SECURITY_ISSUES=0
        
        echo "::group::Hardcoded credentials check"
        if grep -r "password\|secret\|key\|token" AndroidApp/src/ --include="*.kt" --include="*.java" | grep -v "example\|test\|BuildConfig" > android-security-reports/hardcoded-creds.txt; then
          CRED_ISSUES=$(wc -l < android-security-reports/hardcoded-creds.txt)
          SECURITY_ISSUES=$((SECURITY_ISSUES + CRED_ISSUES))
          echo "Found $CRED_ISSUES potential hardcoded credential issues"
        fi
        echo "::endgroup::"
        
        echo "::group::Insecure configuration check"
        if grep -r "android:allowBackup=\"true\"\|android:debuggable=\"true\"" AndroidApp/ > android-security-reports/insecure-config.txt; then
          CONFIG_ISSUES=$(wc -l < android-security-reports/insecure-config.txt)
          SECURITY_ISSUES=$((SECURITY_ISSUES + CONFIG_ISSUES))
          echo "Found $CONFIG_ISSUES insecure configuration issues"
        fi
        echo "::endgroup::"
        
        echo "::group::Permissions analysis"
        grep -r "uses-permission" AndroidApp/src/main/AndroidManifest.xml > android-security-reports/permissions.txt || true
        echo "::endgroup::"
        
        echo "android_security_issues=$SECURITY_ISSUES" >> $GITHUB_OUTPUT
    
    - name: Android quality analysis (Detekt)
      id: android-quality
      run: |
        echo "üìä Running Android quality analysis..."
        mkdir -p android-quality-reports
        
        # Run Detekt analysis
        echo "::group::Detekt static analysis"
        ./gradlew detekt --no-daemon || true
        
        # Copy reports
        cp AndroidApp/build/reports/detekt/detekt.xml android-quality-reports/ || true
        cp AndroidApp/build/reports/detekt/detekt.html android-quality-reports/ || true
        echo "::endgroup::"
        
        # Extract complexity metrics from detekt report
        if [ -f "AndroidApp/build/reports/detekt/detekt.xml" ]; then
          python3 -c '
        import xml.etree.ElementTree as ET
        import json
        
        try:
            tree = ET.parse("AndroidApp/build/reports/detekt/detekt.xml")
            root = tree.getroot()
            
            complexity_issues = []
            for error in root.findall(".//error"):
                source = error.get("source", "")
                if "Complex" in source:
                    complexity_issues.append({
                        "file": error.get("filename", ""),
                        "line": error.get("line", ""),
                        "rule": source,
                        "message": error.get("message", "")
                    })
            
            metrics = {
                "total_complexity_issues": len(complexity_issues),
                "complexity_violations": complexity_issues,
                "threshold_compliant": len(complexity_issues) == 0
            }
            
            with open("android-quality-reports/complexity-metrics.json", "w") as f:
                json.dump(metrics, f, indent=2)
            
            print(f"Android complexity analysis: {len(complexity_issues)} issues found")
            
        except Exception as e:
            print(f"Error analyzing Detekt report: {e}")
            metrics = {"total_complexity_issues": 0, "error": str(e)}
            with open("android-quality-reports/complexity-metrics.json", "w") as f:
                json.dump(metrics, f, indent=2)
        '
        fi
    
    - name: Upload Android security and quality reports
      uses: actions/upload-artifact@v4
      if: always()
      with:
        name: android-security-quality-reports
        path: |
          android-security-reports/
          android-quality-reports/
        retention-days: 30

  # Qodana comprehensive analysis
  qodana-analysis:
    name: Qodana Code Analysis
    runs-on: ubuntu-latest
    if: github.event.inputs.scan_type != 'quick'
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      with:
        fetch-depth: 0
    
    - name: Qodana Scan
      uses: JetBrains/qodana-action@v2025.1
      with:
        args: --baseline,qodana.sarif.json
      env:
        QODANA_TOKEN: ${{ secrets.QODANA_TOKEN }}
    
    - name: Upload Qodana results
      uses: actions/upload-artifact@v4
      if: always()
      with:
        name: qodana-results
        path: |
          qodana.sarif.json
          .qodana/
        retention-days: 30

  # Privacy compliance testing
  privacy-compliance:
    name: Privacy Compliance
    runs-on: ubuntu-latest
    if: github.event.inputs.scan_type == 'full' || github.event.inputs.scan_type == 'security-only' || github.event_name == 'schedule'
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
    
    - name: Set up Python ${{ env.PYTHON_VERSION }}
      uses: actions/setup-python@v5
      with:
        python-version: ${{ env.PYTHON_VERSION }}
        cache: 'pip'
    
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -e .
        pip install -r test-requirements.txt
    
    - name: Run privacy compliance tests
      id: privacy-tests
      run: |
        echo "üîê Running privacy compliance tests..."
        
        # Run privacy-specific tests if they exist
        if [ -f "tests_unified/security/test_privacy_compliance.py" ]; then
          python -m pytest tests_unified/security/test_privacy_compliance.py -v --tb=short \
            --json-report --json-report-file=privacy-test-report.json || true
        elif [ -f "tests/security/test_privacy_compliance.py" ]; then
          python -m pytest tests/security/test_privacy_compliance.py -v --tb=short \
            --json-report --json-report-file=privacy-test-report.json || true
        else
          echo "::warning::Privacy compliance tests not found"
          echo '{"summary": {"failed": 0, "passed": 0, "total": 0}, "tests": []}' > privacy-test-report.json
        fi
        
        # Run TLS authentication tests if they exist
        if [ -f "tests_unified/security/test_tls_authentication.py" ]; then
          python -m pytest tests_unified/security/test_tls_authentication.py -v --tb=short || true
        elif [ -f "tests/security/test_tls_authentication.py" ]; then
          python -m pytest tests/security/test_tls_authentication.py -v --tb=short || true
        else
          echo "::warning::TLS authentication tests not found"
        fi
        
        # Check test results
        if [ -f privacy-test-report.json ]; then
          FAILED_TESTS=$(python -c "
        import json
        try:
            with open('privacy-test-report.json') as f:
                data = json.load(f)
            failed = data.get('summary', {}).get('failed', 0)
            print(failed)
        except:
            print(0)
        " 2>/dev/null || echo "0")
          echo "failed_privacy_tests=$FAILED_TESTS" >> $GITHUB_OUTPUT
        else
          echo "failed_privacy_tests=0" >> $GITHUB_OUTPUT
        fi
    
    - name: Upload privacy compliance results
      uses: actions/upload-artifact@v4
      if: always()
      with:
        name: privacy-compliance-results
        path: |
          privacy-test-report.json
        retention-days: 30

  # Technical debt analysis
  tech-debt-analysis:
    name: Technical Debt Analysis
    runs-on: ubuntu-latest
    if: github.event.inputs.scan_type == 'full' || github.event.inputs.scan_type == 'quality-only' || github.event_name == 'schedule'
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
    
    - name: Set up Python ${{ env.PYTHON_VERSION }}
      uses: actions/setup-python@v5
      with:
        python-version: ${{ env.PYTHON_VERSION }}
        cache: 'pip'
    
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -e .
        pip install -r test-requirements.txt
    
    - name: Technical debt audit
      run: |
        echo "üí≥ Running technical debt analysis..."
        mkdir -p tech-debt-reports
        
        # Run tech debt audit if script exists
        if [ -f "scripts/tech_debt_audit.py" ]; then
          python scripts/tech_debt_audit.py --report --category python \
            --output tech-debt-reports/ || echo "::warning::Tech debt audit failed"
          
          # Generate summary metrics
          python scripts/tech_debt_audit.py --category python --format=json \
            > tech-debt-reports/python-debt-metrics.json 2>/dev/null || echo "::warning::Failed to generate debt metrics"
        else
          echo "::warning::Tech debt audit script not found"
          echo '{"debt_score": 0, "issues": [], "timestamp": "'$(date -Iseconds)'"}' > tech-debt-reports/python-debt-metrics.json
        fi
    
    - name: Upload technical debt reports
      uses: actions/upload-artifact@v4
      if: always()
      with:
        name: tech-debt-reports
        path: tech-debt-reports/
        retention-days: 60

  # Security and quality dashboard
  security-quality-dashboard:
    name: Security & Quality Dashboard
    runs-on: ubuntu-latest
    needs: [python-security-quality, android-security-quality, privacy-compliance, tech-debt-analysis]
    if: always()
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
    
    - name: Download all reports
      uses: actions/download-artifact@v4
      with:
        path: all-reports/
    
    - name: Set up Python
      uses: actions/setup-python@v5
      with:
        python-version: ${{ env.PYTHON_VERSION }}
    
    - name: Generate security and quality dashboard
      run: |
        echo "üìä Generating security and quality dashboard..."
        
        python -c "
        import json
        import os
        from datetime import datetime
        
        # Aggregate all security and quality data
        dashboard_data = {
            'timestamp': datetime.now().isoformat(),
            'workflow_run': '${{ github.run_number }}',
            'commit': '${{ github.sha }}',
            'branch': '${{ github.ref_name }}',
            'python': {},
            'android': {},
            'privacy': {},
            'tech_debt': {},
            'overall_score': 0.0
        }
        
        # Load Python quality data
        try:
            with open('all-reports/python-security-quality-reports/quality-summary.json') as f:
                dashboard_data['python'] = json.load(f)
        except:
            dashboard_data['python'] = {'overall_score': 0.0, 'error': 'No data available'}
        
        # Load Android complexity data
        try:
            with open('all-reports/android-security-quality-reports/complexity-metrics.json') as f:
                dashboard_data['android'] = json.load(f)
        except:
            dashboard_data['android'] = {'total_complexity_issues': 0, 'error': 'No data available'}
        
        # Load privacy compliance data
        try:
            with open('all-reports/privacy-compliance-results/privacy-test-report.json') as f:
                privacy_data = json.load(f)
                dashboard_data['privacy'] = {
                    'tests_passed': privacy_data.get('summary', {}).get('passed', 0),
                    'tests_failed': privacy_data.get('summary', {}).get('failed', 0),
                    'compliance_score': 10.0 if privacy_data.get('summary', {}).get('failed', 0) == 0 else 5.0
                }
        except:
            dashboard_data['privacy'] = {'compliance_score': 0.0, 'error': 'No data available'}
        
        # Load technical debt data
        try:
            with open('all-reports/tech-debt-reports/python-debt-metrics.json') as f:
                dashboard_data['tech_debt'] = json.load(f)
        except:
            dashboard_data['tech_debt'] = {'debt_score': 0.0, 'error': 'No data available'}
        
        # Calculate overall score
        scores = []
        if 'overall_score' in dashboard_data['python']:
            scores.append(dashboard_data['python']['overall_score'])
        if 'compliance_score' in dashboard_data['privacy']:
            scores.append(dashboard_data['privacy']['compliance_score'])
        
        dashboard_data['overall_score'] = sum(scores) / len(scores) if scores else 0.0
        
        # Save dashboard data
        with open('security-quality-dashboard.json', 'w') as f:
            json.dump(dashboard_data, f, indent=2)
        
        print(f'Overall security and quality score: {dashboard_data[\"overall_score\"]:.1f}/10.0')
        "
    
    - name: Generate dashboard HTML
      run: |
        cat > security-quality-dashboard.html << 'EOF'
        <!DOCTYPE html>
        <html>
        <head>
            <title>Security & Quality Dashboard</title>
            <style>
                body { font-family: Arial, sans-serif; margin: 20px; background: #f5f5f5; }
                .container { max-width: 1200px; margin: 0 auto; background: white; padding: 20px; border-radius: 8px; }
                .header { text-align: center; margin-bottom: 30px; }
                .score { font-size: 3em; font-weight: bold; margin: 20px 0; }
                .score.excellent { color: #27ae60; }
                .score.good { color: #f39c12; }
                .score.poor { color: #e74c3c; }
                .metrics { display: grid; grid-template-columns: repeat(auto-fit, minmax(300px, 1fr)); gap: 20px; }
                .metric-card { background: #f8f9fa; padding: 20px; border-radius: 8px; border-left: 4px solid #007bff; }
                .metric-title { font-size: 1.2em; font-weight: bold; margin-bottom: 10px; }
                .metric-value { font-size: 2em; font-weight: bold; }
                .footer { margin-top: 30px; text-align: center; color: #666; }
            </style>
        </head>
        <body>
            <div class="container">
                <div class="header">
                    <h1>üîí Security & Quality Dashboard</h1>
                    <p>Multi-Sensor Recording System - GSR Project</p>
                    <div id="overall-score" class="score">Loading...</div>
                </div>
                
                <div class="metrics" id="metrics">
                    <!-- Metrics will be populated by JavaScript -->
                </div>
                
                <div class="footer">
                    <p>Generated: <span id="timestamp"></span></p>
                    <p>Workflow Run: #${{ github.run_number }} | Commit: ${{ github.sha }}</p>
                </div>
            </div>
            
            <script>
                // Load dashboard data and render
                fetch('security-quality-dashboard.json')
                    .then(response => response.json())
                    .then(data => {
                        // Update overall score
                        const scoreElement = document.getElementById('overall-score');
                        const score = data.overall_score.toFixed(1);
                        scoreElement.textContent = score + '/10.0';
                        
                        if (score >= 8) scoreElement.className = 'score excellent';
                        else if (score >= 6) scoreElement.className = 'score good';
                        else scoreElement.className = 'score poor';
                        
                        // Update timestamp
                        document.getElementById('timestamp').textContent = new Date(data.timestamp).toLocaleString();
                        
                        // Render metrics
                        const metricsContainer = document.getElementById('metrics');
                        
                        // Python metrics
                        if (data.python.overall_score !== undefined) {
                            metricsContainer.innerHTML += 
                                '<div class="metric-card">' +
                                '<div class="metric-title">üêç Python Quality</div>' +
                                '<div class="metric-value">' + data.python.overall_score.toFixed(1) + '/10</div>' +
                                '<p>Critical vulnerabilities: ' + (data.python.critical_vulnerabilities || 0) + '</p>' +
                                '<p>Complex functions: ' + (data.python.complex_functions || 0) + '</p>' +
                                '</div>';
                        }
                        
                        // Android metrics
                        if (data.android.total_complexity_issues !== undefined) {
                            const androidScore = data.android.total_complexity_issues === 0 ? 10.0 : Math.max(10 - data.android.total_complexity_issues, 0);
                            metricsContainer.innerHTML += 
                                '<div class="metric-card">' +
                                '<div class="metric-title">ü§ñ Android Quality</div>' +
                                '<div class="metric-value">' + androidScore.toFixed(1) + '/10</div>' +
                                '<p>Complexity issues: ' + data.android.total_complexity_issues + '</p>' +
                                '</div>';
                        }
                        
                        // Privacy metrics
                        if (data.privacy.compliance_score !== undefined) {
                            metricsContainer.innerHTML += 
                                '<div class="metric-card">' +
                                '<div class="metric-title">üîê Privacy Compliance</div>' +
                                '<div class="metric-value">' + data.privacy.compliance_score.toFixed(1) + '/10</div>' +
                                '<p>Tests passed: ' + (data.privacy.tests_passed || 0) + '</p>' +
                                '<p>Tests failed: ' + (data.privacy.tests_failed || 0) + '</p>' +
                                '</div>';
                        }
                        
                        // Technical debt metrics
                        if (data.tech_debt.debt_score !== undefined) {
                            metricsContainer.innerHTML += 
                                '<div class="metric-card">' +
                                '<div class="metric-title">üí≥ Technical Debt</div>' +
                                '<div class="metric-value">' + data.tech_debt.debt_score.toFixed(1) + '/10</div>' +
                                '</div>';
                        }
                    })
                    .catch(error => {
                        console.error('Error loading dashboard data:', error);
                        document.getElementById('overall-score').textContent = 'Error loading data';
                    });
            </script>
        </body>
        </html>
        EOF
    
    - name: Upload security and quality dashboard
      uses: actions/upload-artifact@v4
      if: always()
      with:
        name: security-quality-dashboard
        path: |
          security-quality-dashboard.html
          security-quality-dashboard.json
        retention-days: 90
    
    - name: Comment PR with security and quality summary
      if: github.event_name == 'pull_request'
      uses: actions/github-script@v7
      with:
        script: |
          const fs = require('fs');
          
          try {
            const dashboardData = JSON.parse(fs.readFileSync('security-quality-dashboard.json', 'utf8'));
            
            const comment = `## üîí Security & Quality Analysis Results
            
            **Overall Score:** ${dashboardData.overall_score.toFixed(1)}/10.0
            
            ### üìä Component Scores
            
            | Component | Score | Status |
            |-----------|-------|--------|
            | üêç Python | ${dashboardData.python.overall_score?.toFixed(1) || 'N/A'}/10 | ${dashboardData.python.overall_score >= 8 ? '‚úÖ Excellent' : dashboardData.python.overall_score >= 6 ? '‚ö†Ô∏è Good' : '‚ùå Needs Work'} |
            | ü§ñ Android | ${dashboardData.android.total_complexity_issues === 0 ? '10.0' : Math.max(10 - dashboardData.android.total_complexity_issues, 0).toFixed(1)}/10 | ${dashboardData.android.total_complexity_issues === 0 ? '‚úÖ Excellent' : '‚ö†Ô∏è Has Issues'} |
            | üîê Privacy | ${dashboardData.privacy.compliance_score?.toFixed(1) || 'N/A'}/10 | ${dashboardData.privacy.tests_failed === 0 ? '‚úÖ Compliant' : '‚ùå Issues Found'} |
            
            ### üö® Security Findings
            - **Critical Vulnerabilities:** ${dashboardData.python.critical_vulnerabilities || 0}
            - **Complex Functions:** ${dashboardData.python.complex_functions || 0}
            - **Android Complexity Issues:** ${dashboardData.android.total_complexity_issues || 0}
            - **Privacy Test Failures:** ${dashboardData.privacy.tests_failed || 0}
            
            ### üìã Recommendations
            ${dashboardData.overall_score >= 8 ? '‚úÖ Excellent security and quality posture! Keep up the good work.' : ''}
            ${dashboardData.overall_score < 8 && dashboardData.overall_score >= 6 ? '‚ö†Ô∏è Good overall score, but consider addressing the issues highlighted above.' : ''}
            ${dashboardData.overall_score < 6 ? '‚ùå Quality and security improvements needed. Please review the detailed reports and address critical issues.' : ''}
            
            <details>
            <summary>üìà View Detailed Dashboard</summary>
            
            The complete security and quality dashboard is available in the workflow artifacts.
            </details>`;
            
            github.rest.issues.createComment({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.repo,
              body: comment
            });
          } catch (error) {
            console.log('Could not create security and quality comment:', error.message);
          }
    
    - name: Fail workflow if critical security issues found
      run: |
        echo "üîç Checking for critical security issues..."
        
        CRITICAL_ISSUES=0
        
        # Check Python critical vulnerabilities
        if [ -f "security-quality-dashboard.json" ]; then
          PYTHON_CRITICAL=$(cat security-quality-dashboard.json | jq -r '.python.critical_vulnerabilities // 0')
          PRIVACY_FAILED=$(cat security-quality-dashboard.json | jq -r '.privacy.tests_failed // 0')
          
          CRITICAL_ISSUES=$((PYTHON_CRITICAL + PRIVACY_FAILED))
          
          echo "Critical vulnerabilities: $PYTHON_CRITICAL"
          echo "Privacy test failures: $PRIVACY_FAILED"
          echo "Total critical issues: $CRITICAL_ISSUES"
          
          if [ "$CRITICAL_ISSUES" -gt 0 ]; then
            echo "‚ùå Critical security issues found - failing workflow"
            exit 1
          else
            echo "‚úÖ No critical security issues found"
          fi
        else
          echo "::warning::Dashboard data not available for security check"
        fi